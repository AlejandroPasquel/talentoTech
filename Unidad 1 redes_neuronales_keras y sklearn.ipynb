{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X,Y=make_circles(n_samples=500,factor=0.5,noise=0.05)\n",
    "\n",
    "#resolucion del mapa de prediccion:\n",
    "res=100\n",
    "\n",
    "#coordenadas del mapa de prediccion:\n",
    "_x0=np.linspace(-1.5,1.5,res)\n",
    "_x1=np.linspace(-1.5,1.5,res)\n",
    "\n",
    "#input con cada combo de coordenadas del mapa de prediccion:\n",
    "\n",
    "_px=np.array(np.meshgrid(_x0,_x1)).T.reshape(-1,2)\n",
    "\n",
    "#objeto vacio a 0.5 del mapa de prediccion :\n",
    "_py=np.zeros((res,res))+0.5\n",
    "\n",
    "#visualizacion del mapa de prediccion:\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.pcolormesh(_x0,_x1,_py,cmap='coolwarm',vmin=0,vmax=1)\n",
    "\n",
    "#visualizacion de la nuve de datos:\n",
    "plt.scatter(X[Y==0,0], X[Y==0,1], c='skyblue')\n",
    "plt.scatter(X[Y==1,0], X[Y==1,1], c='salmon')\n",
    "\n",
    "\n",
    "plt.tick_params(labelbottom=False,labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras:\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr=0.01\n",
    "nn=[2,16,8,1] #numero de neuronas por capa \n",
    "\n",
    "# creamos el objeto que contendra a nuestra red neuronal , como secuencia de capas \n",
    "model = kr.Sequential()\n",
    "\n",
    "#a;adimos la capa 1:\n",
    "l1=model.add(kr.layers.Dense(nn[1],activation='relu'))\n",
    "\n",
    "#a;adimos la capa 2:\n",
    "l2=model.add(kr.layers.Dense(nn[2],activation='relu'))\n",
    "\n",
    "#a;adimos la capa 3:\n",
    "l3=model.add(kr.layers.Dense(nn[3],activation='sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2364 - mae: 0.4828  \n",
      "Epoch 2/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2314 - mae: 0.4778 \n",
      "Epoch 3/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2375 - mae: 0.4845 \n",
      "Epoch 4/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.2338 - mae: 0.4806\n",
      "Epoch 5/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.2342 - mae: 0.4814\n",
      "Epoch 6/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.2375 - mae: 0.4849\n",
      "Epoch 7/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.2343 - mae: 0.4816\n",
      "Epoch 8/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.2365 - mae: 0.4839\n",
      "Epoch 9/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.2329 - mae: 0.4803\n",
      "Epoch 10/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.2349 - mae: 0.4826\n",
      "Epoch 11/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.2322 - mae: 0.4799\n",
      "Epoch 12/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.2343 - mae: 0.4820\n",
      "Epoch 13/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.2320 - mae: 0.4797\n",
      "Epoch 14/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.2331 - mae: 0.4808\n",
      "Epoch 15/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.2333 - mae: 0.4812\n",
      "Epoch 16/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.2342 - mae: 0.4821\n",
      "Epoch 17/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.2332 - mae: 0.4811\n",
      "Epoch 18/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 0.2307 - mae: 0.4785\n",
      "Epoch 19/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2306 - mae: 0.4784\n",
      "Epoch 20/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.2301 - mae: 0.4780\n",
      "Epoch 21/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2303 - mae: 0.4782\n",
      "Epoch 22/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.2304 - mae: 0.4785\n",
      "Epoch 23/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2268 - mae: 0.4747\n",
      "Epoch 24/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.2301 - mae: 0.4782\n",
      "Epoch 25/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.2302 - mae: 0.4784\n",
      "Epoch 26/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.2307 - mae: 0.4789\n",
      "Epoch 27/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.2286 - mae: 0.4766\n",
      "Epoch 28/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.2280 - mae: 0.4760\n",
      "Epoch 29/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2275 - mae: 0.4756\n",
      "Epoch 30/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.2270 - mae: 0.4751\n",
      "Epoch 31/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.2281 - mae: 0.4762\n",
      "Epoch 32/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2279 - mae: 0.4760\n",
      "Epoch 33/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.2290 - mae: 0.4772\n",
      "Epoch 34/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2297 - mae: 0.4780\n",
      "Epoch 35/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.2280 - mae: 0.4762\n",
      "Epoch 36/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.2276 - mae: 0.4759\n",
      "Epoch 37/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.2249 - mae: 0.4730\n",
      "Epoch 38/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.2266 - mae: 0.4747\n",
      "Epoch 39/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.2268 - mae: 0.4751\n",
      "Epoch 40/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 0.2254 - mae: 0.4734\n",
      "Epoch 41/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2268 - mae: 0.4751\n",
      "Epoch 42/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2271 - mae: 0.4754\n",
      "Epoch 43/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.2258 - mae: 0.4739\n",
      "Epoch 44/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2250 - mae: 0.4731\n",
      "Epoch 45/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.2272 - mae: 0.4755\n",
      "Epoch 46/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.2271 - mae: 0.4754\n",
      "Epoch 47/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.2217 - mae: 0.4696\n",
      "Epoch 48/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.2229 - mae: 0.4709\n",
      "Epoch 49/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.2225 - mae: 0.4706\n",
      "Epoch 50/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.2229 - mae: 0.4710\n",
      "Epoch 51/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.2227 - mae: 0.4707\n",
      "Epoch 52/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.2220 - mae: 0.4700\n",
      "Epoch 53/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.2255 - mae: 0.4737\n",
      "Epoch 54/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.2251 - mae: 0.4733\n",
      "Epoch 55/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.2198 - mae: 0.4675\n",
      "Epoch 56/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.2211 - mae: 0.4689\n",
      "Epoch 57/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2207 - mae: 0.4685\n",
      "Epoch 58/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.2210 - mae: 0.4689\n",
      "Epoch 59/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.2215 - mae: 0.4694\n",
      "Epoch 60/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2208 - mae: 0.4687\n",
      "Epoch 61/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.2184 - mae: 0.4662\n",
      "Epoch 62/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.2210 - mae: 0.4689\n",
      "Epoch 63/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.2197 - mae: 0.4676\n",
      "Epoch 64/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2199 - mae: 0.4677\n",
      "Epoch 65/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.2179 - mae: 0.4656\n",
      "Epoch 66/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2170 - mae: 0.4646\n",
      "Epoch 67/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2187 - mae: 0.4665\n",
      "Epoch 68/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2183 - mae: 0.4661\n",
      "Epoch 69/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2158 - mae: 0.4634\n",
      "Epoch 70/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.2161 - mae: 0.4637\n",
      "Epoch 71/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.2186 - mae: 0.4665\n",
      "Epoch 72/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.2163 - mae: 0.4640\n",
      "Epoch 73/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2153 - mae: 0.4628\n",
      "Epoch 74/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.2141 - mae: 0.4614\n",
      "Epoch 75/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.2169 - mae: 0.4646\n",
      "Epoch 76/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2148 - mae: 0.4623\n",
      "Epoch 77/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2136 - mae: 0.4609\n",
      "Epoch 78/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.2133 - mae: 0.4606\n",
      "Epoch 79/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2148 - mae: 0.4623\n",
      "Epoch 80/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.2124 - mae: 0.4596\n",
      "Epoch 81/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.2148 - mae: 0.4623\n",
      "Epoch 82/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.2108 - mae: 0.4579\n",
      "Epoch 83/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2120 - mae: 0.4592\n",
      "Epoch 84/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.2128 - mae: 0.4601\n",
      "Epoch 85/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.2096 - mae: 0.4565\n",
      "Epoch 86/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2113 - mae: 0.4584\n",
      "Epoch 87/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.2082 - mae: 0.4550\n",
      "Epoch 88/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.2060 - mae: 0.4526\n",
      "Epoch 89/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.2066 - mae: 0.4532\n",
      "Epoch 90/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.2079 - mae: 0.4547\n",
      "Epoch 91/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.2081 - mae: 0.4549\n",
      "Epoch 92/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.2077 - mae: 0.4546\n",
      "Epoch 93/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 0.2038 - mae: 0.4502\n",
      "Epoch 94/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.2053 - mae: 0.4519\n",
      "Epoch 95/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.2031 - mae: 0.4495\n",
      "Epoch 96/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.2032 - mae: 0.4494\n",
      "Epoch 97/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2035 - mae: 0.4499\n",
      "Epoch 98/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 0.2000 - mae: 0.4458\n",
      "Epoch 99/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.2008 - mae: 0.4469\n",
      "Epoch 100/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.1995 - mae: 0.4454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29e1093c150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compilamos el modelo definiendo la funcion de coste y el optimizador \n",
    "\n",
    "model.compile(loss='mse',optimizer=kr.optimizers.SGD(learning_rate=lr),metrics=['mae'])\n",
    "\n",
    "#se entrena el modelo\n",
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.35663499\n",
      "Iteration 2, loss = 0.54371572\n",
      "Iteration 3, loss = 0.16782023\n",
      "Iteration 4, loss = 0.13213817\n",
      "Iteration 5, loss = 0.14603330\n",
      "Iteration 6, loss = 0.13753257\n",
      "Iteration 7, loss = 0.12749020\n",
      "Iteration 8, loss = 0.12521197\n",
      "Iteration 9, loss = 0.12568334\n",
      "Iteration 10, loss = 0.12553048\n",
      "Iteration 11, loss = 0.12515068\n",
      "Iteration 12, loss = 0.12502906\n",
      "Iteration 13, loss = 0.12510365\n",
      "Iteration 14, loss = 0.12511649\n",
      "Iteration 15, loss = 0.12503255\n",
      "Iteration 16, loss = 0.12505359\n",
      "Iteration 17, loss = 0.12504799\n",
      "Iteration 18, loss = 0.12520217\n",
      "Iteration 19, loss = 0.12507000\n",
      "Iteration 20, loss = 0.12504453\n",
      "Iteration 21, loss = 0.12509113\n",
      "Iteration 22, loss = 0.12503125\n",
      "Iteration 23, loss = 0.12506819\n",
      "Iteration 24, loss = 0.12507443\n",
      "Iteration 25, loss = 0.12503676\n",
      "Iteration 26, loss = 0.12504435\n",
      "Iteration 27, loss = 0.12508256\n",
      "Iteration 28, loss = 0.12505542\n",
      "Iteration 29, loss = 0.12505810\n",
      "Iteration 30, loss = 0.12509751\n",
      "Iteration 31, loss = 0.12508739\n",
      "Iteration 32, loss = 0.12504565\n",
      "Iteration 33, loss = 0.12509102\n",
      "Iteration 34, loss = 0.12509036\n",
      "Iteration 35, loss = 0.12502349\n",
      "Iteration 36, loss = 0.12505143\n",
      "Iteration 37, loss = 0.12502738\n",
      "Iteration 38, loss = 0.12506064\n",
      "Iteration 39, loss = 0.12520041\n",
      "Iteration 40, loss = 0.12503255\n",
      "Iteration 41, loss = 0.12514162\n",
      "Iteration 42, loss = 0.12504806\n",
      "Iteration 43, loss = 0.12512204\n",
      "Iteration 44, loss = 0.12509207\n",
      "Iteration 45, loss = 0.12506265\n",
      "Iteration 46, loss = 0.12505211\n",
      "Iteration 47, loss = 0.12514323\n",
      "Iteration 48, loss = 0.12514717\n",
      "Iteration 49, loss = 0.12502847\n",
      "Iteration 50, loss = 0.12505268\n",
      "Iteration 51, loss = 0.12504443\n",
      "Iteration 52, loss = 0.12504329\n",
      "Iteration 53, loss = 0.12506061\n",
      "Iteration 54, loss = 0.12505454\n",
      "Iteration 55, loss = 0.12503854\n",
      "Iteration 56, loss = 0.12502016\n",
      "Iteration 57, loss = 0.12503407\n",
      "Iteration 58, loss = 0.12502320\n",
      "Iteration 59, loss = 0.12504828\n",
      "Iteration 60, loss = 0.12511674\n",
      "Iteration 61, loss = 0.12503458\n",
      "Iteration 62, loss = 0.12504435\n",
      "Iteration 63, loss = 0.12503125\n",
      "Iteration 64, loss = 0.12505599\n",
      "Iteration 65, loss = 0.12505223\n",
      "Iteration 66, loss = 0.12507008\n",
      "Iteration 67, loss = 0.12512071\n",
      "Iteration 68, loss = 0.12504263\n",
      "Iteration 69, loss = 0.12513013\n",
      "Iteration 70, loss = 0.12504340\n",
      "Iteration 71, loss = 0.12522188\n",
      "Iteration 72, loss = 0.12505652\n",
      "Iteration 73, loss = 0.12502333\n",
      "Iteration 74, loss = 0.12507890\n",
      "Iteration 75, loss = 0.12512867\n",
      "Iteration 76, loss = 0.12503302\n",
      "Iteration 77, loss = 0.12505234\n",
      "Iteration 78, loss = 0.12506080\n",
      "Iteration 79, loss = 0.12505698\n",
      "Iteration 80, loss = 0.12514525\n",
      "Iteration 81, loss = 0.12504311\n",
      "Iteration 82, loss = 0.12515631\n",
      "Iteration 83, loss = 0.12513696\n",
      "Iteration 84, loss = 0.12511394\n",
      "Iteration 85, loss = 0.12507469\n",
      "Iteration 86, loss = 0.12505068\n",
      "Iteration 87, loss = 0.12503281\n",
      "Iteration 88, loss = 0.12503758\n",
      "Iteration 89, loss = 0.12511586\n",
      "Iteration 90, loss = 0.12503597\n",
      "Iteration 91, loss = 0.12504566\n",
      "Iteration 92, loss = 0.12505821\n",
      "Iteration 93, loss = 0.12508508\n",
      "Iteration 94, loss = 0.12512894\n",
      "Iteration 95, loss = 0.12509064\n",
      "Iteration 96, loss = 0.12507846\n",
      "Iteration 97, loss = 0.12504079\n",
      "Iteration 98, loss = 0.12509419\n",
      "Iteration 99, loss = 0.12502488\n",
      "Iteration 100, loss = 0.12508672\n",
      "Iteration 101, loss = 0.12507594\n",
      "Iteration 102, loss = 0.12512274\n",
      "Iteration 103, loss = 0.12506174\n",
      "Iteration 104, loss = 0.12521385\n",
      "Iteration 105, loss = 0.12509025\n",
      "Iteration 106, loss = 0.12507563\n",
      "Iteration 107, loss = 0.12514942\n",
      "Iteration 108, loss = 0.12503321\n",
      "Iteration 109, loss = 0.12507456\n",
      "Iteration 110, loss = 0.12507452\n",
      "Iteration 111, loss = 0.12507051\n",
      "Iteration 112, loss = 0.12513339\n",
      "Iteration 113, loss = 0.12503557\n",
      "Iteration 114, loss = 0.12505490\n",
      "Iteration 115, loss = 0.12507192\n",
      "Iteration 116, loss = 0.12504302\n",
      "Iteration 117, loss = 0.12508375\n",
      "Iteration 118, loss = 0.12506859\n",
      "Iteration 119, loss = 0.12505813\n",
      "Iteration 120, loss = 0.12518205\n",
      "Iteration 121, loss = 0.12506367\n",
      "Iteration 122, loss = 0.12513693\n",
      "Iteration 123, loss = 0.12509270\n",
      "Iteration 124, loss = 0.12511083\n",
      "Iteration 125, loss = 0.12506634\n",
      "Iteration 126, loss = 0.12506192\n",
      "Iteration 127, loss = 0.12504537\n",
      "Iteration 128, loss = 0.12514541\n",
      "Iteration 129, loss = 0.12512623\n",
      "Iteration 130, loss = 0.12503973\n",
      "Iteration 131, loss = 0.12508325\n",
      "Iteration 132, loss = 0.12505748\n",
      "Iteration 133, loss = 0.12504318\n",
      "Iteration 134, loss = 0.12505717\n",
      "Iteration 135, loss = 0.12506125\n",
      "Iteration 136, loss = 0.12505622\n",
      "Iteration 137, loss = 0.12504400\n",
      "Iteration 138, loss = 0.12504095\n",
      "Iteration 139, loss = 0.12507818\n",
      "Iteration 140, loss = 0.12511272\n",
      "Iteration 141, loss = 0.12504999\n",
      "Iteration 142, loss = 0.12503191\n",
      "Iteration 143, loss = 0.12502025\n",
      "Iteration 144, loss = 0.12507468\n",
      "Iteration 145, loss = 0.12502459\n",
      "Iteration 146, loss = 0.12508586\n",
      "Iteration 147, loss = 0.12503710\n",
      "Iteration 148, loss = 0.12504240\n",
      "Iteration 149, loss = 0.12518566\n",
      "Iteration 150, loss = 0.12504408\n",
      "Iteration 151, loss = 0.12507770\n",
      "Iteration 152, loss = 0.12507204\n",
      "Iteration 153, loss = 0.12508702\n",
      "Iteration 154, loss = 0.12504636\n",
      "Iteration 155, loss = 0.12505533\n",
      "Iteration 156, loss = 0.12503512\n",
      "Iteration 157, loss = 0.12507232\n",
      "Iteration 158, loss = 0.12503918\n",
      "Iteration 159, loss = 0.12505360\n",
      "Iteration 160, loss = 0.12504927\n",
      "Iteration 161, loss = 0.12520609\n",
      "Iteration 162, loss = 0.12503915\n",
      "Iteration 163, loss = 0.12505886\n",
      "Iteration 164, loss = 0.12506386\n",
      "Iteration 165, loss = 0.12505645\n",
      "Iteration 166, loss = 0.12503487\n",
      "Iteration 167, loss = 0.12503230\n",
      "Iteration 168, loss = 0.12503587\n",
      "Iteration 169, loss = 0.12504875\n",
      "Iteration 170, loss = 0.12506162\n",
      "Iteration 171, loss = 0.12506347\n",
      "Iteration 172, loss = 0.12505524\n",
      "Iteration 173, loss = 0.12513704\n",
      "Iteration 174, loss = 0.12502000\n",
      "Iteration 175, loss = 0.12506449\n",
      "Iteration 176, loss = 0.12504444\n",
      "Iteration 177, loss = 0.12503872\n",
      "Iteration 178, loss = 0.12505502\n",
      "Iteration 179, loss = 0.12503600\n",
      "Iteration 180, loss = 0.12506458\n",
      "Iteration 181, loss = 0.12503733\n",
      "Iteration 182, loss = 0.12503815\n",
      "Iteration 183, loss = 0.12502557\n",
      "Iteration 184, loss = 0.12502976\n",
      "Iteration 185, loss = 0.12507574\n",
      "Iteration 186, loss = 0.12503469\n",
      "Iteration 187, loss = 0.12506652\n",
      "Iteration 188, loss = 0.12510575\n",
      "Iteration 189, loss = 0.12504365\n",
      "Iteration 190, loss = 0.12505629\n",
      "Iteration 191, loss = 0.12502922\n",
      "Iteration 192, loss = 0.12504510\n",
      "Iteration 193, loss = 0.12506212\n",
      "Iteration 194, loss = 0.12503235\n",
      "Iteration 195, loss = 0.12505589\n",
      "Iteration 196, loss = 0.12504170\n",
      "Iteration 197, loss = 0.12505640\n",
      "Iteration 198, loss = 0.12511203\n",
      "Iteration 199, loss = 0.12501262\n",
      "Iteration 200, loss = 0.12510745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhinn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(batch_size=64, hidden_layer_sizes=(16, 8, 1),\n",
       "             learning_rate_init=0.01, n_iter_no_change=1000, solver=&#x27;sgd&#x27;,\n",
       "             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(batch_size=64, hidden_layer_sizes=(16, 8, 1),\n",
       "             learning_rate_init=0.01, n_iter_no_change=1000, solver=&#x27;sgd&#x27;,\n",
       "             verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(batch_size=64, hidden_layer_sizes=(16, 8, 1),\n",
       "             learning_rate_init=0.01, n_iter_no_change=1000, solver='sgd',\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#con sklearn:\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "clf=MLPRegressor(solver='sgd',\n",
    "                                   learning_rate_init=lr,\n",
    "                                   hidden_layer_sizes=tuple(nn[1:]),\n",
    "                                   verbose=True,\n",
    "                                   n_iter_no_change=1000,\n",
    "                                   batch_size=64)\n",
    "\n",
    "clf.fit(X,Y)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando sklearn con el dataset iris:\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris=load_iris()\n",
    "X,y=iris.data, iris.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "#explorando los datos (opcional)\n",
    "print(type(iris))\n",
    "print(iris.keys())\n",
    "print(iris['data'])\n",
    "print(iris['target'])\n",
    "print(iris['target_names'])\n",
    "print(iris['DESCR'])\n",
    "print(iris['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando la intancia de MLPclassifier \n",
    "\n",
    "mlp_clf=MLPClassifier(hidden_layer_sizes=(100),\n",
    "                      activation='relu',\n",
    "                      solver='adam',\n",
    "                      max_iter=100,\n",
    "                      random_state=42,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.16374923\n",
      "Iteration 2, loss = 1.14090611\n",
      "Iteration 3, loss = 1.11857816\n",
      "Iteration 4, loss = 1.09677375\n",
      "Iteration 5, loss = 1.07547149\n",
      "Iteration 6, loss = 1.05468504\n",
      "Iteration 7, loss = 1.03440573\n",
      "Iteration 8, loss = 1.01462373\n",
      "Iteration 9, loss = 0.99535820\n",
      "Iteration 10, loss = 0.97658926\n",
      "Iteration 11, loss = 0.95833257\n",
      "Iteration 12, loss = 0.94053852\n",
      "Iteration 13, loss = 0.92322169\n",
      "Iteration 14, loss = 0.90638373\n",
      "Iteration 15, loss = 0.89000670\n",
      "Iteration 16, loss = 0.87408395\n",
      "Iteration 17, loss = 0.85861030\n",
      "Iteration 18, loss = 0.84357120\n",
      "Iteration 19, loss = 0.82895431\n",
      "Iteration 20, loss = 0.81476466\n",
      "Iteration 21, loss = 0.80097410\n",
      "Iteration 22, loss = 0.78759157\n",
      "Iteration 23, loss = 0.77460302\n",
      "Iteration 24, loss = 0.76199129\n",
      "Iteration 25, loss = 0.74975377\n",
      "Iteration 26, loss = 0.73786826\n",
      "Iteration 27, loss = 0.72632581\n",
      "Iteration 28, loss = 0.71511871\n",
      "Iteration 29, loss = 0.70424319\n",
      "Iteration 30, loss = 0.69368183\n",
      "Iteration 31, loss = 0.68342580\n",
      "Iteration 32, loss = 0.67346953\n",
      "Iteration 33, loss = 0.66380608\n",
      "Iteration 34, loss = 0.65442161\n",
      "Iteration 35, loss = 0.64531278\n",
      "Iteration 36, loss = 0.63647902\n",
      "Iteration 37, loss = 0.62790342\n",
      "Iteration 38, loss = 0.61957863\n",
      "Iteration 39, loss = 0.61148527\n",
      "Iteration 40, loss = 0.60361466\n",
      "Iteration 41, loss = 0.59597076\n",
      "Iteration 42, loss = 0.58855743\n",
      "Iteration 43, loss = 0.58136358\n",
      "Iteration 44, loss = 0.57437150\n",
      "Iteration 45, loss = 0.56758016\n",
      "Iteration 46, loss = 0.56097952\n",
      "Iteration 47, loss = 0.55455113\n",
      "Iteration 48, loss = 0.54829175\n",
      "Iteration 49, loss = 0.54219766\n",
      "Iteration 50, loss = 0.53626159\n",
      "Iteration 51, loss = 0.53048210\n",
      "Iteration 52, loss = 0.52484566\n",
      "Iteration 53, loss = 0.51933866\n",
      "Iteration 54, loss = 0.51394846\n",
      "Iteration 55, loss = 0.50869354\n",
      "Iteration 56, loss = 0.50356710\n",
      "Iteration 57, loss = 0.49857160\n",
      "Iteration 58, loss = 0.49370008\n",
      "Iteration 59, loss = 0.48894487\n",
      "Iteration 60, loss = 0.48429908\n",
      "Iteration 61, loss = 0.47974886\n",
      "Iteration 62, loss = 0.47529331\n",
      "Iteration 63, loss = 0.47093384\n",
      "Iteration 64, loss = 0.46667067\n",
      "Iteration 65, loss = 0.46249978\n",
      "Iteration 66, loss = 0.45841914\n",
      "Iteration 67, loss = 0.45442291\n",
      "Iteration 68, loss = 0.45050855\n",
      "Iteration 69, loss = 0.44667746\n",
      "Iteration 70, loss = 0.44292801\n",
      "Iteration 71, loss = 0.43926405\n",
      "Iteration 72, loss = 0.43567120\n",
      "Iteration 73, loss = 0.43215951\n",
      "Iteration 74, loss = 0.42871948\n",
      "Iteration 75, loss = 0.42534205\n",
      "Iteration 76, loss = 0.42201917\n",
      "Iteration 77, loss = 0.41875279\n",
      "Iteration 78, loss = 0.41554234\n",
      "Iteration 79, loss = 0.41238463\n",
      "Iteration 80, loss = 0.40928512\n",
      "Iteration 81, loss = 0.40623752\n",
      "Iteration 82, loss = 0.40323632\n",
      "Iteration 83, loss = 0.40027444\n",
      "Iteration 84, loss = 0.39735268\n",
      "Iteration 85, loss = 0.39447038\n",
      "Iteration 86, loss = 0.39162936\n",
      "Iteration 87, loss = 0.38882549\n",
      "Iteration 88, loss = 0.38605547\n",
      "Iteration 89, loss = 0.38331954\n",
      "Iteration 90, loss = 0.38062197\n",
      "Iteration 91, loss = 0.37796519\n",
      "Iteration 92, loss = 0.37534717\n",
      "Iteration 93, loss = 0.37276083\n",
      "Iteration 94, loss = 0.37020149\n",
      "Iteration 95, loss = 0.36766960\n",
      "Iteration 96, loss = 0.36516474\n",
      "Iteration 97, loss = 0.36267665\n",
      "Iteration 98, loss = 0.36021595\n",
      "Iteration 99, loss = 0.35777846\n",
      "Iteration 100, loss = 0.35536449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhinn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=100, max_iter=100, random_state=42,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=100, max_iter=100, random_state=42,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=100, max_iter=100, random_state=42,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entrenando el modelo \n",
    "mlp_clf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "[1 0 2 1 2 0 1 2 1 1 2 0 0 0 0 2 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred=mlp_clf.predict(X_test_scaled)\n",
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# precision del modelo:\n",
    "\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "print(\"Precision del modelo \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando MLPRegresor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# Explorando los datos (Opcional)\n",
    "type(housing)\n",
    "housing.keys()\n",
    "housing['data']\n",
    "housing['target']\n",
    "housing['target_names']\n",
    "housing['DESCR']\n",
    "housing['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar las características para un mejor rendimiento del modelo\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg = MLPRegressor(hidden_layer_sizes=(100,),\n",
    "                       activation='relu',\n",
    "                       solver='adam',\n",
    "                       max_iter=100,\n",
    "                       random_state=42,\n",
    "                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.62056447\n",
      "Iteration 2, loss = 0.43678846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.32700527\n",
      "Iteration 4, loss = 0.28069940\n",
      "Iteration 5, loss = 0.24814135\n",
      "Iteration 6, loss = 0.22803342\n",
      "Iteration 7, loss = 0.21538976\n",
      "Iteration 8, loss = 0.20787968\n",
      "Iteration 9, loss = 0.20154389\n",
      "Iteration 10, loss = 0.19743378\n",
      "Iteration 11, loss = 0.19321222\n",
      "Iteration 12, loss = 0.18961729\n",
      "Iteration 13, loss = 0.18678600\n",
      "Iteration 14, loss = 0.18383630\n",
      "Iteration 15, loss = 0.18157601\n",
      "Iteration 16, loss = 0.17968086\n",
      "Iteration 17, loss = 0.17775103\n",
      "Iteration 18, loss = 0.17538371\n",
      "Iteration 19, loss = 0.17423819\n",
      "Iteration 20, loss = 0.17407294\n",
      "Iteration 21, loss = 0.17085613\n",
      "Iteration 22, loss = 0.16995187\n",
      "Iteration 23, loss = 0.16823352\n",
      "Iteration 24, loss = 0.16798530\n",
      "Iteration 25, loss = 0.16717835\n",
      "Iteration 26, loss = 0.16566984\n",
      "Iteration 27, loss = 0.16730781\n",
      "Iteration 28, loss = 0.16499618\n",
      "Iteration 29, loss = 0.16261953\n",
      "Iteration 30, loss = 0.16145474\n",
      "Iteration 31, loss = 0.16053131\n",
      "Iteration 32, loss = 0.16002333\n",
      "Iteration 33, loss = 0.16125255\n",
      "Iteration 34, loss = 0.15863582\n",
      "Iteration 35, loss = 0.15835131\n",
      "Iteration 36, loss = 0.15795060\n",
      "Iteration 37, loss = 0.15703766\n",
      "Iteration 38, loss = 0.15707574\n",
      "Iteration 39, loss = 0.15768516\n",
      "Iteration 40, loss = 0.15525691\n",
      "Iteration 41, loss = 0.15632172\n",
      "Iteration 42, loss = 0.15467901\n",
      "Iteration 43, loss = 0.15438915\n",
      "Iteration 44, loss = 0.15556876\n",
      "Iteration 45, loss = 0.15329744\n",
      "Iteration 46, loss = 0.15273177\n",
      "Iteration 47, loss = 0.15307344\n",
      "Iteration 48, loss = 0.15369159\n",
      "Iteration 49, loss = 0.15240098\n",
      "Iteration 50, loss = 0.15143071\n",
      "Iteration 51, loss = 0.15112755\n",
      "Iteration 52, loss = 0.15083169\n",
      "Iteration 53, loss = 0.15061975\n",
      "Iteration 54, loss = 0.17536085\n",
      "Iteration 55, loss = 0.15573187\n",
      "Iteration 56, loss = 0.15049969\n",
      "Iteration 57, loss = 0.14988656\n",
      "Iteration 58, loss = 0.15022315\n",
      "Iteration 59, loss = 0.14961153\n",
      "Iteration 60, loss = 0.14848394\n",
      "Iteration 61, loss = 0.14950369\n",
      "Iteration 62, loss = 0.14843954\n",
      "Iteration 63, loss = 0.14811978\n",
      "Iteration 64, loss = 0.14766317\n",
      "Iteration 65, loss = 0.14793107\n",
      "Iteration 66, loss = 0.14733359\n",
      "Iteration 67, loss = 0.14800560\n",
      "Iteration 68, loss = 0.14665149\n",
      "Iteration 69, loss = 0.14686777\n",
      "Iteration 70, loss = 0.14665771\n",
      "Iteration 71, loss = 0.14612037\n",
      "Iteration 72, loss = 0.14639346\n",
      "Iteration 73, loss = 0.14671723\n",
      "Iteration 74, loss = 0.14576906\n",
      "Iteration 75, loss = 0.15060883\n",
      "Iteration 76, loss = 0.14555955\n",
      "Iteration 77, loss = 0.14514246\n",
      "Iteration 78, loss = 0.14553115\n",
      "Iteration 79, loss = 0.14643439\n",
      "Iteration 80, loss = 0.14501085\n",
      "Iteration 81, loss = 0.14468993\n",
      "Iteration 82, loss = 0.14489975\n",
      "Iteration 83, loss = 0.14516740\n",
      "Iteration 84, loss = 0.14435448\n",
      "Iteration 85, loss = 0.14397719\n",
      "Iteration 86, loss = 0.14633622\n",
      "Iteration 87, loss = 0.14389402\n",
      "Iteration 88, loss = 0.14379916\n",
      "Iteration 89, loss = 0.14337806\n",
      "Iteration 90, loss = 0.14402555\n",
      "Iteration 91, loss = 0.14472118\n",
      "Iteration 92, loss = 0.14661691\n",
      "Iteration 93, loss = 0.15462744\n",
      "Iteration 94, loss = 0.14386535\n",
      "Iteration 95, loss = 0.14275879\n",
      "Iteration 96, loss = 0.14295641\n",
      "Iteration 97, loss = 0.14219076\n",
      "Iteration 98, loss = 0.14180756\n",
      "Iteration 99, loss = 0.14206889\n",
      "Iteration 100, loss = 0.14286992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhinn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_reg.fit(X_train_scaled,y_train)\n",
    "\n",
    "y_pred=mlp_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio: 0.33\n"
     ]
    }
   ],
   "source": [
    "# calculando el error cuadratuco medio\n",
    "\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(f\"Error cuadrático medio: {mse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
